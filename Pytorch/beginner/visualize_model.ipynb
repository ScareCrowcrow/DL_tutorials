{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a “Projector” to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking model training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing trained models with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
